{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbvoWQJdwglcgmtUKPAC2y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KCachel/FairRankTune/blob/main/examples/1_quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "aPfbFCZkmYxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to install [FairRankTune](https://https://github.com/KCachel/FairRankTune)."
      ],
      "metadata": {
        "id": "tfF1MsSEjhbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install FairRankTune"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqYw3v4_jx74",
        "outputId": "81d65357-3474-4b24-f820-47bc755f7d52"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: FairRankTune in /usr/local/lib/python3.10/dist-packages (0.0.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to import FairRankTune along with some other packages."
      ],
      "metadata": {
        "id": "UH63dmzEkAZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import FairRankTune as frt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from FairRankTune import RankTune, Metrics, Rankers"
      ],
      "metadata": {
        "id": "FyEGSwpWj9CZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RankTune (Data Generation)\n",
        "The [RankTune](https://https://kcachel.github.io/FairRankTune/RankTune/) data generator allows for quickly generating high-volumes of unfair rankings.\n",
        "\n",
        "RankTune is a pseudo-stochastic data generation method for creating fairness-aware ranked lists using the fairness concept of statistical parity. Inlcuded in the `RankTune` module, it creates ranking(s) based on the `phi` representativeness parameter. When `phi = 0` then the generated ranked list(s) does not represent groups fairly, and as `phi` increases groups are represented more and more fairly; thus `phi = 1` groups are fairly represented. RankTune uses a [pseudo-random process](https://kcachel.github.io/FairRankTune/RankTune/#how-does-it-work) to generate fairness-aware ranked data. RankTune can generate ranked data from [user provided group sizes](https://kcachel.github.io/FairRankTune/RankTune/#using-group-sizes), from [existing datasets](https://kcachel.github.io/FairRankTune/RankTune/#using-an-existing-dataset), along with [producing relevance scores](https://kcachel.github.io/FairRankTune/RankTune/#generating-scores-with-the-ranking) accompanying the ranked list(s).\n"
      ],
      "metadata": {
        "id": "QAYDtiE9kxXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this overview we will generate data from from `group_proportions`, a numpy array with each group's proportion of the total items,`num_items`, by using the `ScoredGenFromGroups()` function.  Scores are generated from either a normal or uniform distribution by setting the `score_dist` parameter to either ```normal``` or ```uniform```."
      ],
      "metadata": {
        "id": "ydxjjxOXlnic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate a biased (phi = 0.1) ranking of 1000 items, with four groups of 100, 200, 300, and 400 items each.\n",
        "group_proportions = np.asarray([.1, .2, .3, .4]) #Array of group proportions\n",
        "num_items = 1000 #1000 items to be in the generated ranking\n",
        "phi = 0.1\n",
        "r_cnt = 1 #Generate 1 ranking\n",
        "seed = 10 #For reproducability\n",
        "score_dist = \"uniform\"\n",
        "ranking_df, item_group_dict, scores_df = frt.RankTune.ScoredGenFromGroups(group_proportions, num_items, phi, r_cnt, score_dist, seed)"
      ],
      "metadata": {
        "id": "lW8DefNxlmyS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics (Evaluate Data Generation & Fair Ranking)\n",
        "FairRankTune provides 10 [fair ranking metrics](https://https://kcachel.github.io/FairRankTune/Metrics/) in the `Metrics` module. In this overview we will use group fairness of Exposure [EXP](https://https://kcachel.github.io/FairRankTune/Metrics/#group-exposure-exp) and Normalized-discounted KL-divergence [NDKL](https://kcachel.github.io/FairRankTune/Metrics/#normalized-discounted-kl-divergence-ndkl).\n",
        "\n",
        "A key functionality of FairRankTune is providing toolkit users multiple choices for how to calculate a given top-level fairness metric. For instance, for EXP,  `Metrics` offers seven ways of calculating a top-level exposure metric (e.g., min-max ratios, max absolute difference, L-2 norms of per-group exposures, etc.).\n",
        "\n",
        "In this notebook we will calculate EXP with a `'MinMaxRatio'`, so it's range is [0, 1] where *1 is most fair*. NDKL is not meta-metric composable and it's range is [0, âˆž] where *0 is most fair*."
      ],
      "metadata": {
        "id": "vAnurFtQkRJ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate EXP fairness of previously generated ranking"
      ],
      "metadata": {
        "id": "n6-EPeOenxcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate EXP with a MinMaxRatio\n",
        "EXP_minmax, avg_exposures = frt.Metrics.EXP(ranking_df, item_group_dict, 'MinMaxRatio')\n",
        "print(\"EXP (most fair at 1): \", EXP_minmax, \"Average exposures for each group: \", avg_exposures)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MvJ_VhrkQ0r",
        "outputId": "f4711f91-8da0-41f8-c38b-0b657c3ea0b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXP (most fair at 1):  0.511665941043515 Average exposures for each group:  {0: 0.20498798214669187, 1: 0.13126425437156242, 2: 0.11461912123646827, 3: 0.10488536878769836}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the EXP indicates the generated ranking is pretty unfair. This is expected since we set `phi = 0.1` and `phi` ranges from unfair (`phi = 0`) to fairest representatation (`phi = 1`).\n",
        "\n"
      ],
      "metadata": {
        "id": "N3C5s3sBoDok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate NDKL fairness of previously generated ranking"
      ],
      "metadata": {
        "id": "q7DYkFEmoX_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate NDKL\n",
        "NDKL= frt.Metrics.NDKL(ranking_df, item_group_dict)\n",
        "print(\"NDKL (most fair at 0): \", NDKL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCdmENQ3ocrC",
        "outputId": "1a80eb4d-0dae-4b17-89f8-e0aa58285710"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NDKL (most fair at 0):  0.7858194402275921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that NDKL also indicates the generated ranking is pretty unfair."
      ],
      "metadata": {
        "id": "BNH5L3hgotUt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rankers (Re-rank generated ranking to be fair)\n",
        "\n",
        "FairRankTune provides [fair ranking algorithms](https://kcachel.github.io/FairRankTune/Rankers/#supported-fair-ranking-algorithms) in the `Rankers` module. These fair ranking algorithms can be used to re-rank a given ranking with the objective of making the resulting ranking fair.\n",
        "\n",
        "Here we will use the [Epsilon-Greedy algorithm](https://kcachel.github.io/FairRankTune/Rankers/#epsilon-greedy-re-ranker). Epsilon-Greedy takes as input a ranking and repeatedly swaps pairs of items so that each item has probability $\\epsilon$ (`epsilon`) of swapping with a random item below it. It does not require a specific notion of fairness or prior knowledge of group distributions. It does use random swapping, thus it is recommended to set a random seed for reproducability. To learn more see [Feng et al.](https://doi.org/10.1609/aaai.v36i11.21445)."
      ],
      "metadata": {
        "id": "MMfLGms-ox4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Rerank using Epsilon-Greedy\n",
        "seed = 2 #For reproducability\n",
        "epsilon = .6\n",
        "reranking_df, item_group_d, reranking_scores = frt.Rankers.EPSILONGREEDY(ranking_df, item_group_dict, scores_df, epsilon, seed)"
      ],
      "metadata": {
        "id": "GEmQIBk7pWN-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will compare the EXP and NDKL metrics to those calculated prior to the fair ranking algorithm."
      ],
      "metadata": {
        "id": "1jg3_ZlcqAPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate EXP with a MinMaxRatio post Epsilon-Greedy\n",
        "EXPpost, avg_exposures_post= frt.Metrics.EXP(reranking_df, item_group_d, 'MinMaxRatio')\n",
        "print(\"EXP (more fair at 1) after Epsilon-Greedy: \", EXPpost, \"avg_exposures after Epsilon-Greedy: \", avg_exposures_post)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1S5CRnO7p_mk",
        "outputId": "2f3c520e-9de8-495b-dab1-539abb00fb7a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXP (more fair at 1) after Epsilon-Greedy:  0.7489965299172665 avg_exposures after Epsilon-Greedy:  {0: 0.15469032884066963, 1: 0.12633302018059972, 2: 0.12003629416481872, 3: 0.1158625195134224}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see EXP increased from 0.511 to 0.748 indicating the ranking was adjusted to be fairer."
      ],
      "metadata": {
        "id": "mL7tqsz8qReF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate NDKL post Epsilon-Greedy\n",
        "NDKLpost= frt.Metrics.NDKL(reranking_df, item_group_d)\n",
        "print(\"NDKL (more fair at 0) after Epsilon-Greedy: \", NDKLpost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db40LUWEqhCN",
        "outputId": "c4c2a110-c690-4f00-81e0-b45088149381"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NDKL (more fair at 0) after Epsilon-Greedy:  0.14287220595846148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see NDKL decreased (became more fair) from 0.785 to 0.145 after Epsilon-Greedy."
      ],
      "metadata": {
        "id": "Mr5VrIw6qssG"
      }
    }
  ]
}